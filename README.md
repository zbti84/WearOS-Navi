# WearOS-Navi
한성대학교 2022년 1학기 캡스톤디자인

android project
https://github.com/zbti84/wearosnavi

mqtt project
https://github.com/zbti84/mqtt

## 수상성적
![msedge_wuANsfR6Dh](https://user-images.githubusercontent.com/74825481/172051899-b6e051c4-ebdb-4be1-8186-216b0ced2ac1.png)


## 개발개요
지도 API' + 'GPS' + '마이크 기능' + '진동 기능'을 이용하여 음성안내 및 시각적인 정보
없이 워치의 진동 표현으로 길을 안내할 수 있는 시각장애인용 길안내 어플.
 화면을 보며 길을 따라가야 하는 길 찾기 어플은 시각장애인들이 사용하기에는 많은 어려움이 있다. 
 
 또한 음성으로 길을 알려주는 어플은 사람이 많은 곳에선 잘 들리지 않아 사용에 어려움이 있고 만약 이어폰을 낀다면 길 안내 음성은 잘 들리지만 오히려 주변 소리가 잘 안 들리게 되는 경우가 많다.
 게다가 휴대폰을 손에 들고 다니는 점에 대한 불편함도 있는데, 시각장애인들은 앞에 있는 장애물을 피하기 위해 보조대로 짚어가며 다니곤 한다. 이럴 때 다른 손에 휴대폰까지 들고 있다면 보다 많이 불편하게 느끼게 된다.
 이러한 어려움을 해소하기 위해 스마트 워치 내 진동으로 길을 안내하는 방법을 선택하였다.
 
 Tmap에서 지도 api를 받아와 목적지를 음성으로 입력받으면 그 목적지까지의 경로를 진동으로 표현한다.
 또한 스마트워치를 사용하면 손에 휴대폰을 쥐고 있지 않고 그저 팔목에 착용만 하면 된다는 장점이 있다.



## 프로젝트 구조도
![image](https://user-images.githubusercontent.com/74825481/171761600-a8b87165-215d-48d4-b0d8-374fe18f06a5.png)

사용자가 음성을 텍스트로 변환하여 이를 목적지로 인식하고 목적지까지의 길을 안내한다.

음성인식은 kakao api를 사용하여 구현하였다. 지도는 tmap api를 사용하여 얻어왔다.

추가적으로 모니터링을 위해 mqtt를 사용하여 모니터링 시스템을 구축했다.


## 시연영상

(1)
![Hnet-image](https://user-images.githubusercontent.com/74825481/172054898-e860f8ff-c2ca-485b-ac36-3b25dbc08645.gif)

(2)
![Hnet-image (1)](https://user-images.githubusercontent.com/74825481/172054899-93d013de-19ed-46c4-97ef-fd44f3b69bcc.gif)



## 기대효과
* 편리성 : 
앱 내 기능들은 워치의 물리버튼을 클릭함으로써 사용할 수 있어 편리성을 향상시킴. 


* 안전성 : 
음성 안내를 최소화로 주변 소리에 집중력이 높아져 보행시 안전성이 올라감.

* 비시각적 정보 : 
길 안내에 화면을 사용하지 않고 진동으로 표현하기 때문에 시각적인 정보를 최소화 했다.


* 실시간 정보 : 
사용자의 상황을 제3자가 실시간으로 파악하여 즉각적인 피드백이 가능함.



## 사용 기술

|개발환경|개발도구|개발언어|하드웨어|주요기술|
|------|---|---|---|---|
|window10|Android Studio, Visaul Studio|Kotlin, JavaScript, html|Galaxy watch 4|API통신, STT, GPS, MQTT |


